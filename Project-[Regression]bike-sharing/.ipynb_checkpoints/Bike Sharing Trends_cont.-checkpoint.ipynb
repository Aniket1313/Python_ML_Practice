{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pydotplus\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_hour = pd.read_csv(\"data/hour.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_hour.rename(\n",
    "    columns = {\n",
    "     'instant' : \"record_id\",\n",
    "     'dteday' : \"datetime\",\n",
    "     'holiday' : \"is_holiday\",\n",
    "     'workingday' : \"is_workingday\",\n",
    "     'weathersit' : \"weather_condition\",\n",
    "     'hum' : \"humidity\",\n",
    "     'mnth' : \"month\",\n",
    "     'cnt' : \"total_count\",\n",
    "     'hr' : \"hour\",\n",
    "     'yr' : \"year\"},\n",
    "    inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_hour['datetime'] = pd.to_datetime(df_hour.datetime)\n",
    "\n",
    "df_hour['season'] = df_hour.season.astype('category')\n",
    "df_hour['is_holiday'] = df_hour.is_holiday.astype('category')\n",
    "df_hour['weekday'] = df_hour.weekday.astype('category')\n",
    "df_hour['weather_condition'] = df_hour.weather_condition.astype('category')\n",
    "df_hour['is_workingday'] = df_hour.is_workingday.astype('category')\n",
    "df_hour['month'] = df_hour.month.astype('category')\n",
    "df_hour['year'] = df_hour.year.astype('category')\n",
    "df_hour['hour'] = df_hour.hour.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare for training samples\n",
    "# Encode Categoricals (One Hot Encoding)\n",
    "def fit_transform_one_hot_encoding(df, col_name):\n",
    "    '''\n",
    "    This function performs one hot encoding for the specified\n",
    "        column.\n",
    "    \n",
    "    Args:\n",
    "        df(pandas.DataFrame): the data frame containing the mentioned column name\n",
    "        col_name: the column to be one hot encoded\n",
    "    Returns:\n",
    "        tuple: label_encoder, one_hot_encoder, transformed column as pandas Series      \n",
    "    '''\n",
    "    \n",
    "    # label encode the column\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    encoded_labels = le.fit_transform(df[col_name])\n",
    "    df[col_name + '_label'] = encoded_labels\n",
    "    \n",
    "    # one hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
    "    feature_labels = [col_name + '_' + str(cls_label) for cls_label in le.classes_]\n",
    "    features_df = pd.DataFrame(feature_arr, columns = feature_labels)\n",
    "    \n",
    "    return le, ohe, features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare for the test samples\n",
    "def transform_ohe(df,le,ohe,col_name):\n",
    "    \n",
    "    encoded_labels = le.fit_transform(df[col_name])\n",
    "    df[col_name + '_label'] = encoded_labels\n",
    "    \n",
    "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
    "    feature_labels = [col_name + '_' + str(cls_label) for cls_label in le.classes_]\n",
    "    features_df = pd.DataFrame(feature_arr, columns = feature_labels)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour = df_hour.reindex(np.random.permutation(df_hour.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17379*0.66\n",
    "17379-11470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_features(df_hour):\n",
    "    \n",
    "    # \tlongitude\tlatitude\thousing_median_age\ttotal_rooms\ttotal_bedrooms\tpopulation\thouseholds\tmedian_income\tmedian_house_value\n",
    "    selected_features = df_hour[[\n",
    " 'record_id',\n",
    " 'datetime',\n",
    " 'season',\n",
    " 'year',\n",
    " 'month',\n",
    " 'hour',\n",
    " 'is_holiday',\n",
    " 'weekday',\n",
    " 'is_workingday',\n",
    " 'weather_condition',\n",
    " 'temp',\n",
    " 'atemp',\n",
    " 'humidity',\n",
    " 'windspeed']]\n",
    "    \n",
    "    processed_features = selected_features.copy()\n",
    "    #processed_features[\"rooms_per_person\"] = california_housing_dataframe[\"total_rooms\"] / california_housing_dataframe[\"population\"]\n",
    "    \n",
    "    return processed_features\n",
    "\n",
    "def preprocess_targets(df_hour):\n",
    "    \n",
    "    output_targets = pd.DataFrame()\n",
    "    output_targets['total_count'] = df_hour['total_count']\n",
    "    return output_targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the first 11470 (out of 17379) examples for training.\n",
    "training_examples = preprocess_features(df_hour.head(11470))\n",
    "training_targets = preprocess_targets(df_hour.head(11470))\n",
    "\n",
    "# Choose the last 5909 (out of 17379) examples for validation.\n",
    "validation_examples = preprocess_features(df_hour.tail(5909))\n",
    "validation_targets = preprocess_targets(df_hour.tail(5909))\n",
    "\n",
    "print(\"Training set::{}{}\".format(training_examples.shape, training_targets.shape))\n",
    "print(\"Validation set::{}\".format(validation_examples.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples.reset_index(inplace = True)\n",
    "training_targets = training_targets.reset_index()\n",
    "\n",
    "validation_examples.reset_index(inplace = True)\n",
    "validation_targets = validation_targets.reset_index()\n",
    "\n",
    "print(\"Training set::{}{}\".format(training_examples.shape, training_targets.shape))\n",
    "print(\"Validation set::{}\".format(validation_examples.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_feature_cols = ['temp','humidity','windspeed',\n",
    "                        'hour','weekday','month','year']\n",
    "subset_cat_features =  ['season','is_holiday',\n",
    "                        'weather_condition','is_workingday']\n",
    "# cat_attr_list = ['season', 'is_holiday',\n",
    "#                  'weather_condition','is_workingday',\n",
    "#                  'hour','weekday',\n",
    "#                  'month','year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_training_input_fn(df,col_name):\n",
    "    \"\"\"This function performs one hot encoding for the specified\n",
    "        column.\n",
    "    Args:\n",
    "        df(pandas.DataFrame): the data frame containing the mentioned column name\n",
    "        col_name: the column to be one hot encoded\n",
    "    Returns:\n",
    "        tuple: label_encoder, one_hot_encoder, transformed column as pandas Series\n",
    "    \"\"\"\n",
    "    # label-encode feature (integer encoded)\n",
    "    label_encoders = preprocessing.LabelEncoder()\n",
    "    integer_encoded = label_encoders.fit_transform(df[col_name])\n",
    "    \n",
    "    # make one hot encoding (binary encoded)\n",
    "    onehot_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    \n",
    "    feature_arr = onehot_encoder.fit_transform(integer_encoded)\n",
    "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in label_encoders.classes_]\n",
    "    feature_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
    "    \n",
    "    return label_encoders, onehot_encoder, feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_predict_input_fn(df, col_name, label_encoders, onehot_encoder):\n",
    "    \n",
    "    # find the encoded label\n",
    "    col_labels = label_encoders.transform(df[col_name])\n",
    "    \n",
    "    # make one hot encoding\n",
    "    col_labels = col_labels.reshape(len(col_labels), 1)\n",
    "    \n",
    "    feature_arr = onehot_encoder.fit_transform(col_labels)\n",
    "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in label_encoders.classes_]\n",
    "    feature_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
    "    \n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_encoded_category_features = []\n",
    "\n",
    "for col in subset_cat_features:\n",
    "    return_obj = create_training_input_fn(training_examples, col)\n",
    "    training_encoded_category_features.append({'label_enc':return_obj[0],\n",
    "                                               'ohe_enc':return_obj[1],\n",
    "                                               'feature_df':return_obj[2],\n",
    "                                               'col_name':col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df_list = [training_examples[numeric_feature_cols]]\n",
    "feature_df_list.extend([enc['feature_df'] for enc in training_encoded_category_features])\n",
    "\n",
    "training_input_fn = pd.concat(feature_df_list, axis=1)\n",
    "training_targets = training_targets.total_count.values.reshape(-1,1)\n",
    "\n",
    "print(\"Shape::{}\".format(training_input_fn.shape))\n",
    "print(\"Shape::{}\".format(training_targets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Decision Tree based Regression\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth = 4, \n",
    "                            min_samples_split = 5, \n",
    "                            max_leaf_nodes = 10)\n",
    "\n",
    "dtr.fit(training_input_fn, training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.score(training_input_fn, training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ********  '''\n",
    "dot_data = tree.export_graphviz(dtr, out_file = None)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf(\"bikeshare.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fine-tuning the hyperparameters\n",
    "# grid search or random search?\n",
    "\n",
    "# For GridSearchCV()\n",
    "# The dictionary basically provides a list of feasible values \n",
    "# for each of the hyperparameters that we want to fine-tune. \n",
    "\n",
    "param_grid = {\"criterion\": ['mse', 'mae'],\n",
    "              \"min_samples_split\": [10, 20 ,40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"min_samples_leaf\": [20, 40, 100],\n",
    "              \"max_leaf_nodes\": [5, 20, 100, 500, 800]}\n",
    "\n",
    "grid_cv_dtr = GridSearchCV(dtr, param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reaaaaaally time-consuming\n",
    "grid_cv_dtr.fit(training_input_fn, training_targets)\n",
    "\n",
    "print(\"R-Squared::{}\".format(grid_cv_dtr.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_dtr.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=grid_cv_dtr.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.pointplot(data=df[['mean_test_score',\n",
    "                      'param_max_leaf_nodes',\n",
    "                      'param_max_depth']],\n",
    "              y='mean_test_score',\n",
    "              x='param_max_depth',\n",
    "              hue='param_max_leaf_nodes',\n",
    "              ax=ax)\n",
    "\n",
    "ax.set(title=\"Effect of Depth and Leaf Nodes on Model Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Residual Plot '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = grid_cv_dtr.best_estimator_.predict(training_input_fn)\n",
    "residuals = training_targets.flatten()-predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(training_targets.flatten(), residuals)\n",
    "ax.axhline(lw=2,color='black')\n",
    "ax.set_xlabel('Observed')\n",
    "ax.set_ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r2_scores = cross_val_score(grid_cv_dtr.best_estimator_, \n",
    "                            training_input_fn, \n",
    "                            training_targets, \n",
    "                            cv=10)\n",
    "\n",
    "mse_scores = cross_val_score(grid_cv_dtr.best_estimator_, \n",
    "                             training_input_fn, \n",
    "                             training_targets, \n",
    "                             cv=10,\n",
    "                             scoring='neg_mean_squared_error')\\\n",
    "\n",
    "print(\"avg R-squared::{}\".format(np.mean(r2_scores)))\n",
    "print(\"MSE::{}\".format(np.mean(mse_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Testing the model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_dtr_model = grid_cv_dtr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create_predict_input_fn(df, col_name, label_encoders, onehot_encoder):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_encoded_category_features = []\n",
    "\n",
    "for enc in training_encoded_category_features:\n",
    "    col_name = enc['col_name']\n",
    "    label_encoders = enc['label_enc']\n",
    "    onehot_encoder = enc['ohe_enc']\n",
    "    validation_encoded_category_features.append({'feature_df':create_predict_input_fn(validation_examples, \n",
    "                                                                                    col_name, \n",
    "                                                                                    label_encoders, \n",
    "                                                                                    onehot_encoder),\n",
    "                                               'col_name':col_name})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_validation_input_fn = \n",
    "\n",
    "\n",
    "validation_feature_df_list = [validation_examples[numeric_feature_cols]]\n",
    "validation_feature_df_list.extend([enc['feature_df'] for enc in validation_encoded_category_features])\n",
    "\n",
    "predict_validation_input_fn = pd.concat(validation_feature_df_list, axis=1)\n",
    "validation_targets = validation_targets.total_count.values.reshape(-1,1)\n",
    "\n",
    "print(\"Shape::{}\".format(predict_validation_input_fn.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = best_dtr_model.predict(predict_validation_input_fn)\n",
    "residuals = validation_targets.flatten() - predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r2_score = best_dtr_model.score(predict_validation_input_fn, validation_targets)\n",
    "print(\"R-squared::{}\".format(r2_score))\n",
    "print(\"MSE: %.2f\"\n",
    "      % metrics.mean_squared_error(validation_targets, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(validation_targets.flatten(), residuals)\n",
    "ax.axhline(lw=2,color='black')\n",
    "ax.set_xlabel('Observed')\n",
    "ax.set_ylabel('Residual')\n",
    "plt.show()\n",
    "\n",
    "r2_score = grid_cv_dtr.best_estimator_.score(predict_validation_input_fn, validation_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
