{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import text_normalizer as tn\n",
    "import model_evaluation_utils as meu\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'movie_reviews.csv')\n",
    "\n",
    "# take a peek at the data\n",
    "print(dataset.head())\n",
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# build train and test datasets\n",
    "train_reviews = reviews[:35000]\n",
    "train_sentiments = sentiments[:35000]\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize datasets\n",
    "norm_train_reviews = tn.normalize_corpus(train_reviews)\n",
    "norm_test_reviews = tn.normalize_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "with open('train_result.txt','r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "documents = data.split(\",\")\n",
    "docs = [review[2:-1] for review in documents]\n",
    "docs[-1] = docs[-1][:-1] # special for the last one\n",
    "\n",
    "norm_train_reviews = docs\n",
    "\n",
    "with open('test_result.txt','r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "test_documents = data.split(\",\")\n",
    "test_docs = [review[2:-1] for review in test_documents]\n",
    "test_docs[-1] = test_docs[-1][:-1]\n",
    "\n",
    "norm_test_reviews = test_docs # special for the last one\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "print(len(norm_train_reviews))\n",
    "print(len(norm_test_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize train & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_train = [tn.tokenizer.tokenize(text) for text in norm_train_reviews]\n",
    "tokenized_test = [tn.tokenizer.tokenize(text) for text in norm_test_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocabulary Mapping (word to index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 80051\n",
      "Sample slice of vocabulary map: {'happen': 11, 'first': 12, 'thing': 13, 'strike': 14, 'brutality': 15, 'unflinch': 16, 'scene': 17, 'violence': 18, 'set': 19, 'word': 20}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# build word to index vocabulary\n",
    "token_counter = Counter([token for review in tokenized_train for token in review])\n",
    "vocab_map = {item[0]: index + 1 for index, item in enumerate(dict(token_counter).items())}\n",
    "max_index = np.max(list(vocab_map.values()))\n",
    "vocab_map['PAD_INDEX'] = 0\n",
    "vocab_map['NOT_FOUND_INDEX'] = max_index + 1\n",
    "vocab_size = len(vocab_map)\n",
    "\n",
    "# view vocabulary size and part of the vocabulary map\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Sample slice of vocabulary map:', dict(list(vocab_map.items())[10:20]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and Pad datasets & Encode prediction class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of train review vectors: 1442\n",
      "Train review vectors shape: (35000, 1442)  Test review vectors shape: (15000, 1442)\n"
     ]
    }
   ],
   "source": [
    "# get max length of train corpus and initialize label encoder\n",
    "le = LabelEncoder()\n",
    "num_classes = 2 # 1 for positive and 0 for negative\n",
    "max_len = np.max([len(review) for review in tokenized_train])\n",
    "\n",
    "# train review data corpus\n",
    "# convert tokenized text review into numeric vectors\n",
    "train_X = [[vocab_map[token] for token in tokenized_review] \\\n",
    "           for tokenized_review in tokenized_train]\n",
    "train_X = sequence.pad_sequences(train_X, maxlen = max_len)\n",
    "\n",
    "# Train prediction class labels\n",
    "# convert text sentiment labesl (negative\\positive) into binary encodings (0/1)\n",
    "train_y = le.fit_transform(train_sentiments)\n",
    "\n",
    "# Test review data corpus\n",
    "# convert tokenized text review into numeric vectors\n",
    "test_X = [[vocab_map[token] if vocab_map.get(token) else vocab_map['NOT_FOUND_INDEX']\n",
    "           for token in tokenized_review] \\\n",
    "              for tokenized_review in tokenized_test]\n",
    "test_X = sequence.pad_sequences(test_X, maxlen = max_len)\n",
    "\n",
    "# Test prediction class labels\n",
    "# convert text sentiment labesl (negative\\positive) into binary encodings (0/1)\n",
    "test_y = le.fit_transform(test_sentiments)\n",
    "\n",
    "# view vector shapes\n",
    "print('Max length of train review vectors:', max_len)\n",
    "print('Train review vectors shape:', train_X.shape,\n",
    "      ' Test review vectors shape:', test_X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the LSTM Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, SpatialDropout1D\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# dimension for dense embeddings for each token\n",
    "EMBEDDING_DIM = 128\n",
    "# total LSTM units\n",
    "LSTM_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab_size, \n",
    "                    output_dim = EMBEDDING_DIM, \n",
    "                    input_length = max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(LSTM_DIM, \n",
    "               dropout = 0.2,\n",
    "               recurrent_dropout = 0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"75pt\" viewBox=\"0.00 0.00 1121.48 75.00\" width=\"1121pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 71)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-71 1117.4844,-71 1117.4844,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4876891360 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4876891360</title>\n",
       "<polygon fill=\"none\" points=\"0,-.5 0,-66.5 181.2969,-66.5 181.2969,-.5 0,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90.6484\" y=\"-51.3\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"0,-44.5 181.2969,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"43.3345\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"86.6689,-22.5 86.6689,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.5034\" y=\"-29.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"0,-22.5 181.2969,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"45.3242\" y=\"-7.3\">(None, 1442)</text>\n",
       "<polyline fill=\"none\" points=\"90.6484,-.5 90.6484,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.9727\" y=\"-7.3\">(None, 1442)</text>\n",
       "</g>\n",
       "<!-- 4876890520 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4876890520</title>\n",
       "<polygon fill=\"none\" points=\"217.2969,-.5 217.2969,-66.5 426.5938,-66.5 426.5938,-.5 217.2969,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321.9453\" y=\"-51.3\">Embedding</text>\n",
       "<polyline fill=\"none\" points=\"217.2969,-44.5 426.5938,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267.6313\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"317.9658,-22.5 317.9658,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"371.8003\" y=\"-29.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"217.2969,-22.5 426.5938,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.6211\" y=\"-7.3\">(None, 1442)</text>\n",
       "<polyline fill=\"none\" points=\"307.9453,-.5 307.9453,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"367.2695\" y=\"-7.3\">(None, 1442, 128)</text>\n",
       "</g>\n",
       "<!-- 4876891360&#45;&gt;4876890520 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4876891360-&gt;4876890520</title>\n",
       "<path d=\"M181.3992,-33.5C189.859,-33.5 198.5054,-33.5 207.1455,-33.5\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"207.2738,-37.0001 217.2738,-33.5 207.2737,-30.0001 207.2738,-37.0001\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4876891584 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4876891584</title>\n",
       "<polygon fill=\"none\" points=\"462.5938,-.5 462.5938,-66.5 699.8906,-66.5 699.8906,-.5 462.5938,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581.2422\" y=\"-51.3\">SpatialDropout1D</text>\n",
       "<polyline fill=\"none\" points=\"462.5938,-44.5 699.8906,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"519.9282\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"577.2627,-22.5 577.2627,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"638.0972\" y=\"-29.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"462.5938,-22.5 699.8906,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"521.918\" y=\"-7.3\">(None, 1442, 128)</text>\n",
       "<polyline fill=\"none\" points=\"581.2422,-.5 581.2422,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"640.5664\" y=\"-7.3\">(None, 1442, 128)</text>\n",
       "</g>\n",
       "<!-- 4876890520&#45;&gt;4876891584 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4876890520-&gt;4876891584</title>\n",
       "<path d=\"M426.6639,-33.5C435.1499,-33.5 443.784,-33.5 452.4133,-33.5\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"452.532,-37.0001 462.5319,-33.5 452.5319,-30.0001 452.532,-37.0001\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4380526072 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4380526072</title>\n",
       "<polygon fill=\"none\" points=\"735.8906,-.5 735.8906,-66.5 931.1875,-66.5 931.1875,-.5 735.8906,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"833.5391\" y=\"-51.3\">LSTM</text>\n",
       "<polyline fill=\"none\" points=\"735.8906,-44.5 931.1875,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"782.7251\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"829.5596,-22.5 829.5596,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"879.894\" y=\"-29.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"735.8906,-22.5 931.1875,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"795.2148\" y=\"-7.3\">(None, 1442, 128)</text>\n",
       "<polyline fill=\"none\" points=\"854.5391,-.5 854.5391,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"892.8633\" y=\"-7.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 4876891584&#45;&gt;4380526072 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4876891584-&gt;4380526072</title>\n",
       "<path d=\"M700.0029,-33.5C708.5441,-33.5 717.1306,-33.5 725.6051,-33.5\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"725.8761,-37.0001 735.876,-33.5 725.876,-30.0001 725.8761,-37.0001\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4876892536 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4876892536</title>\n",
       "<polygon fill=\"none\" points=\"967.1875,-.5 967.1875,-66.5 1113.4844,-66.5 1113.4844,-.5 967.1875,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1040.3359\" y=\"-51.3\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"967.1875,-44.5 1113.4844,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1001.522\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1035.8564,-22.5 1035.8564,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1074.1909\" y=\"-29.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"967.1875,-22.5 1113.4844,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1005.5117\" y=\"-7.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1043.8359,-.5 1043.8359,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1078.6602\" y=\"-7.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 4380526072&#45;&gt;4876892536 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>4380526072-&gt;4876892536</title>\n",
       "<path d=\"M931.4871,-33.5C940.0223,-33.5 948.6071,-33.5 957.0081,-33.5\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"957.1486,-37.0001 967.1486,-33.5 957.1486,-30.0001 957.1486,-37.0001\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
    "                 rankdir='LR').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reaaaaaaaaaaaaaaaaaaaally slow!! even with GPU\n",
    "batch_size = 100\n",
    "model.fit(train_X, train_y, epochs = 5, \n",
    "          batch_size = batch_size, shuffle = True,\n",
    "          validation_split = 0.1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Train on 31500 samples, validate on 3500 samples\n",
    "Epoch 1/5\n",
    "31500/31500 [==============================] - 1404s 45ms/step - loss: 0.0573 - acc: 0.9814 - val_loss: 0.5339 - val_acc: 0.8706\n",
    "Epoch 2/5\n",
    "19000/31500 [=================>............] - ETA: 8:49 - loss: 0.0426 - acc: 0.987231500/31500 [==============================] - 1368s 43ms/step - loss: 0.0448 - acc: 0.9867 - val_loss: 0.5247 - val_acc: 0.8640\n",
    "Epoch 3/5\n",
    "31500/31500 [==============================] - 1370s 43ms/step - loss: 0.0410 - acc: 0.9867 - val_loss: 0.5889 - val_acc: 0.8657\n",
    "Epoch 4/5\n",
    " 4900/31500 [===>..........................] - ETA: 18:45 - loss: 0.0247 - acc: 0.991831500/31500 [==============================] - 1370s 44ms/step - loss: 0.0301 - acc: 0.9901 - val_loss: 0.5821 - val_acc: 0.8663\n",
    "Epoch 5/5\n",
    "31500/31500 [==============================] - 1360s 43ms/step - loss: 0.0267 - acc: 0.9918 - val_loss: 0.6416 - val_acc: 0.8651\n",
    "<keras.callbacks.History at 0x7f85d3f73438>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = model.predict_classes(test_X)\n",
    "predictions = le.inverse_transform(pred_test.flatten())\n",
    "\n",
    "meu.display_model_performance_metrics(\n",
    "    true_labels=test_sentiments,\n",
    "    predicted_labels=predictions, \n",
    "    classes=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Model Performance metrics:\n",
    "------------------------------\n",
    "Accuracy: 0.8714\n",
    "Precision: 0.8716\n",
    "Recall: 0.8714\n",
    "F1 Score: 0.8714\n",
    "\n",
    "Model Classification report:\n",
    "------------------------------\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   positive       0.86      0.88      0.87      7510\n",
    "   negative       0.88      0.86      0.87      7490\n",
    "\n",
    "avg / total       0.87      0.87      0.87     15000\n",
    "\n",
    "\n",
    "Prediction Confusion Matrix:\n",
    "------------------------------\n",
    "                 Predicted:         \n",
    "                   positive negative\n",
    "Actual: positive       6637      873\n",
    "        negative       1056     6434\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
