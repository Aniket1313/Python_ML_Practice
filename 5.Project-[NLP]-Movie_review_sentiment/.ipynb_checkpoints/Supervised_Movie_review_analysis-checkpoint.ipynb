{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import text_normalizer as tn\n",
    "import model_evaluation_utils as meu\n",
    "\n",
    "np.set_printoptions(precision = 2, linewidth = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'movie_reviews.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = np.array(data['review'])\n",
    "sentiments = np.array(data['sentiment'])\n",
    "\n",
    "train_reviews = reviews[:35000]\n",
    "train_sentiments = sentiments[:35000]\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize dataset\n",
    "norm_train_reviews = tn.normalize_corpus(train_reviews)\n",
    "norm_test_reviews = tn.normalize_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('train_result.txt', 'a') as the_file:\n",
    "#      the_file.write(str(norm_train_reviews))\n",
    "\n",
    "# with open('test_result.txt', 'a') as the_file:\n",
    "#      the_file.write(str(norm_test_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Supervised Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build BOW features on train reviews\n",
    "cv = CountVectorizer(binary = False,\n",
    "                     min_df = 0.0,\n",
    "                     max_df = 1.0,\n",
    "                     ngram_range = (1, 2))\n",
    "cv_train_features = cv.fit_transform(norm_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build TFIDF features on train reviews\n",
    "tv = TfidfVectorizer(use_idf = True,\n",
    "                     min_df = 0.0,\n",
    "                     max_df = 1.0,\n",
    "                     ngram_range = (1,2))\n",
    "tv_train_features = tv.fit_transform(norm_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform test reviews into features\n",
    "cv_test_features = cv.transform(norm_test_reviews)\n",
    "tv_test_features = tv.transform(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (35000, 2104735)  Test features shape: (15000, 2104735)\n",
      "TFIDF model:> Train features shape: (35000, 2104735)  Test features shape: (15000, 2104735)\n"
     ]
    }
   ],
   "source": [
    "print('BOW model:> Train features shape:', cv_train_features.shape,\n",
    "              ' Test features shape:', cv_test_features.shape)\n",
    "print('TFIDF model:> Train features shape:', tv_train_features.shape,\n",
    "              ' Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training, Prediction and Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty = 'l2', \n",
    "                        max_iter = 100,\n",
    "                        C = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1Logistic Regression model on BOW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.9056\n",
      "Precision: 0.9056\n",
      "Recall: 0.9056\n",
      "F1 Score: 0.9056\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.90      0.91      0.91      7510\n",
      "   negative       0.91      0.90      0.91      7490\n",
      "\n",
      "avg / total       0.91      0.91      0.91     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6822      688\n",
      "        negative        728     6762\n"
     ]
    }
   ],
   "source": [
    "lr_bow_predictions = meu.train_predict_model(classifier=lr,\n",
    "                                             train_features=cv_train_features, \n",
    "                                             train_labels=train_sentiments,\n",
    "                                             test_features=cv_test_features, \n",
    "                                             test_labels=test_sentiments)\n",
    "\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, \n",
    "                                      predicted_labels=lr_bow_predictions,\n",
    "                                      classes=['positive', 'negative'])\n",
    "\n",
    "# We get an overall F1-Score and model accuracy of 91%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  1.2Logistic Regression model on TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.9056\n",
      "Precision: 0.9056\n",
      "Recall: 0.9056\n",
      "F1 Score: 0.9056\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.90      0.91      0.91      7510\n",
      "   negative       0.91      0.90      0.91      7490\n",
      "\n",
      "avg / total       0.91      0.91      0.91     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6822      688\n",
      "        negative        728     6762\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf_predictions = meu.train_predict_model(\n",
    "    classifier=lr,\n",
    "    train_features=cv_train_features, \n",
    "    train_labels=train_sentiments,\n",
    "    test_features=cv_test_features, \n",
    "    test_labels=test_sentiments)\n",
    "\n",
    "meu.display_model_performance_metrics(\n",
    "    true_labels = test_sentiments, \n",
    "    predicted_labels = lr_tfidf_predictions,\n",
    "    classes=['positive', 'negative'])\n",
    "\n",
    "# We get an overall F1-Score and model accuracy of 90%,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. SVM(linear) --- SCGClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SGDClassifier(loss = 'hinge', n_iter = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 SVM model on BOW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyuwei/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.9005\n",
      "Precision: 0.9005\n",
      "Recall: 0.9005\n",
      "F1 Score: 0.9005\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.90      0.90      0.90      7510\n",
      "   negative       0.90      0.90      0.90      7490\n",
      "\n",
      "avg / total       0.90      0.90      0.90     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6742      768\n",
      "        negative        725     6765\n"
     ]
    }
   ],
   "source": [
    "svm_bow_predictions = meu.train_predict_model(classifier=svm,\n",
    "                                             train_features=cv_train_features, \n",
    "                                             train_labels=train_sentiments,\n",
    "                                             test_features=cv_test_features, \n",
    "                                             test_labels=test_sentiments)\n",
    "\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, \n",
    "                                      predicted_labels=svm_bow_predictions,\n",
    "                                      classes=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SVM model on TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyuwei/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8955\n",
      "Precision: 0.8961\n",
      "Recall: 0.8955\n",
      "F1 Score: 0.8954\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.91      0.88      0.89      7510\n",
      "   negative       0.88      0.91      0.90      7490\n",
      "\n",
      "avg / total       0.90      0.90      0.90     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6581      929\n",
      "        negative        639     6851\n"
     ]
    }
   ],
   "source": [
    "svm_tfidf_predictions = meu.train_predict_model(\n",
    "    classifier=svm,\n",
    "    train_features=cv_train_features, \n",
    "    train_labels=train_sentiments,\n",
    "    test_features=cv_test_features, \n",
    "    test_labels=test_sentiments)\n",
    "\n",
    "meu.display_model_performance_metrics(\n",
    "    true_labels = test_sentiments, \n",
    "    predicted_labels = svm_tfidf_predictions,\n",
    "    classes=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newer Supervised Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Dense\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment class label map: {'negative': 0, 'positive': 1}\n",
      "Sample test label transformation:\n",
      "----------------------------------- \n",
      "Actual Labels: ['negative' 'positive' 'negative'] \n",
      "Encoded Labels: [0 1 0] \n",
      "One hot encoded Labels:\n",
      " [[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwe can see from the preceding sample outputs how our sentiment class labels \\nhave been encoded into numeric representations. [one-hot encoded vectors]\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoded = LabelEncoder()\n",
    "num_classes = 2\n",
    "# tokenize train reviews & encode train labels\n",
    "tokenized_train = [tn.tokenizer.tokenize(text) for text in norm_train_reviews]\n",
    "y_tr = label_encoded.fit_transform(train_sentiments)\n",
    "y_train = keras.utils.to_categorical(y_tr, num_classes)\n",
    "\n",
    "# tokenize test reviews & encode test labels \n",
    "tokenized_test = [tn.tokenizer.tokenize(text) for text in norm_test_reviews]\n",
    "y_te = label_encoded.fit_transform(test_sentiments)\n",
    "y_test = keras.utils.to_categorical(y_te, num_classes)\n",
    "\n",
    "# print class label encoding map and encoded labels\n",
    "print('Sentiment class label map:', dict(zip(label_encoded.classes_,\n",
    "                                             label_encoded.transform(label_encoded.classes_))))\n",
    "\n",
    "print('Sample test label transformation:\\n'+'-'*35,\n",
    "      '\\nActual Labels:', test_sentiments[:3], '\\nEncoded Labels:', y_te[:3], \n",
    "      '\\nOne hot encoded Labels:\\n', y_test[:3])\n",
    "\n",
    "'''\n",
    "we can see from the preceding sample outputs how our sentiment class labels \n",
    "have been encoded into numeric representations. [one-hot encoded vectors]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering with word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build word2vec model\n",
    "w2v_num_features = 500\n",
    "w2v_model = gensim.models.Word2Vec(tokenized_train, \n",
    "                                   size = w2v_num_features,\n",
    "                                   window = 150,\n",
    "                                   min_count = 10,\n",
    "                                   sample = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
    "    \n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    \n",
    "    def average_word_vectors(words, model, vocabulary, num_features):\n",
    "        feature_vector = np.zeros((num_features,), dtype = 'float64')\n",
    "        nwords = 0.\n",
    "        \n",
    "        for word in words:\n",
    "            if word in vocabulary:\n",
    "                nwords += 1.\n",
    "                feature_vector = np.add(feature_vector, model[word])\n",
    "        \n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "        return feature_vector\n",
    "    \n",
    "    features = [average_word_vectors(tokenized_sentence, \n",
    "                                     model, \n",
    "                                     vocabulary, \n",
    "                                     num_features) for tokenized_sentence in corpus]\n",
    "    return np.array(features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyuwei/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# generate averaged word vector features from word2vec model\n",
    "avg_wv_train_features = averaged_word2vec_vectorizer(\n",
    "    corpus=tokenized_train, \n",
    "    model=w2v_model,\n",
    "    num_features=500)\n",
    "\n",
    "avg_wv_test_features = averaged_word2vec_vectorizer(\n",
    "    corpus=tokenized_test, \n",
    "    model=w2v_model,\n",
    "    num_features=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate word vector feature from with GloVe model\n",
    "train_nlp = [tn.nlp(item) for item in norm_train_reviews]\n",
    "train_glove_features = np.array([item.vector for item in train_nlp])\n",
    "\n",
    "test_nlp = [tn.nlp(item) for item in norm_test_reviews]\n",
    "test_glove_features = np.array([item.vector for item in test_nlp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec model:> Train features shape: (35000, 500)  Test features shape: (15000, 500)\n",
      "GloVe model:> Train features shape: (35000, 384)  Test features shape: (15000, 384)\n"
     ]
    }
   ],
   "source": [
    "print('Word2Vec model:> Train features shape:', avg_wv_train_features.shape, \n",
    "      ' Test features shape:', avg_wv_test_features.shape)\n",
    "\n",
    "print('GloVe model:> Train features shape:', train_glove_features.shape, \n",
    "      ' Test features shape:', test_glove_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with deep neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Deep neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_deepnn_architecture(num_input_features):\n",
    "    dnn_model = Sequential()\n",
    "    dnn_model.add(Dense(512, activation = 'relu', input_shape = (num_input_features,)))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(512, activation = 'relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(512, activation = 'relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(2))\n",
    "    dnn_model.add(Activation('softmax'))\n",
    "    \n",
    "    dnn_model.compile(loss = 'categorical_crossentropy',\n",
    "                      optimizer = 'adam',\n",
    "                      metrics = ['accuracy'])\n",
    "    return dnn_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_dnn = construct_deepnn_architecture(num_input_features = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize sample deep architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"701pt\" viewBox=\"0.00 0.00 225.51 701.00\" width=\"226pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 697)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-697 221.5107,-697 221.5107,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 6470967192 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>6470967192</title>\n",
       "<polygon fill=\"none\" points=\"0,-648.5 0,-692.5 217.5107,-692.5 217.5107,-648.5 0,-648.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0967\" y=\"-666.3\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"78.1934,-648.5 78.1934,-692.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106.0278\" y=\"-677.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"78.1934,-670.5 133.8623,-670.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106.0278\" y=\"-655.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"133.8623,-648.5 133.8623,-692.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.6865\" y=\"-677.3\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"133.8623,-670.5 217.5107,-670.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.6865\" y=\"-655.3\">(None, 500)</text>\n",
       "</g>\n",
       "<!-- 6470967024 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>6470967024</title>\n",
       "<polygon fill=\"none\" points=\"13.6035,-567.5 13.6035,-611.5 203.9072,-611.5 203.9072,-567.5 13.6035,-567.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0967\" y=\"-585.3\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64.5898,-567.5 64.5898,-611.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4243\" y=\"-596.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64.5898,-589.5 120.2588,-589.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4243\" y=\"-574.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-567.5 120.2588,-611.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.083\" y=\"-596.3\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-589.5 203.9072,-589.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.083\" y=\"-574.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 6470967192&#45;&gt;6470967024 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>6470967192-&gt;6470967024</title>\n",
       "<path d=\"M108.7554,-648.3664C108.7554,-640.1516 108.7554,-630.6579 108.7554,-621.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.2555,-621.6068 108.7554,-611.6068 105.2555,-621.6069 112.2555,-621.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6470965736 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>6470965736</title>\n",
       "<polygon fill=\"none\" points=\"7.7656,-486.5 7.7656,-530.5 209.7451,-530.5 209.7451,-486.5 7.7656,-486.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0967\" y=\"-504.3\">Dropout</text>\n",
       "<polyline fill=\"none\" points=\"70.4277,-486.5 70.4277,-530.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2622\" y=\"-515.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"70.4277,-508.5 126.0967,-508.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2622\" y=\"-493.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"126.0967,-486.5 126.0967,-530.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9209\" y=\"-515.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"126.0967,-508.5 209.7451,-508.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9209\" y=\"-493.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 6470967024&#45;&gt;6470965736 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>6470967024-&gt;6470965736</title>\n",
       "<path d=\"M108.7554,-567.3664C108.7554,-559.1516 108.7554,-549.6579 108.7554,-540.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.2555,-540.6068 108.7554,-530.6068 105.2555,-540.6069 112.2555,-540.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6470294048 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>6470294048</title>\n",
       "<polygon fill=\"none\" points=\"13.6035,-405.5 13.6035,-449.5 203.9072,-449.5 203.9072,-405.5 13.6035,-405.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0967\" y=\"-423.3\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64.5898,-405.5 64.5898,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4243\" y=\"-434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64.5898,-427.5 120.2588,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4243\" y=\"-412.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-405.5 120.2588,-449.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.083\" y=\"-434.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-427.5 203.9072,-427.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.083\" y=\"-412.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 6470965736&#45;&gt;6470294048 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>6470965736-&gt;6470294048</title>\n",
       "<path d=\"M108.7554,-486.3664C108.7554,-478.1516 108.7554,-468.6579 108.7554,-459.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.2555,-459.6068 108.7554,-449.6068 105.2555,-459.6069 112.2555,-459.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4825030896 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4825030896</title>\n",
       "<polygon fill=\"none\" points=\"7.7656,-324.5 7.7656,-368.5 209.7451,-368.5 209.7451,-324.5 7.7656,-324.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0967\" y=\"-342.3\">Dropout</text>\n",
       "<polyline fill=\"none\" points=\"70.4277,-324.5 70.4277,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2622\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"70.4277,-346.5 126.0967,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2622\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"126.0967,-324.5 126.0967,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9209\" y=\"-353.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"126.0967,-346.5 209.7451,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9209\" y=\"-331.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 6470294048&#45;&gt;4825030896 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>6470294048-&gt;4825030896</title>\n",
       "<path d=\"M108.7554,-405.3664C108.7554,-397.1516 108.7554,-387.6579 108.7554,-378.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.2555,-378.6068 108.7554,-368.6068 105.2555,-378.6069 112.2555,-378.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4315335200 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>4315335200</title>\n",
       "<polygon fill=\"none\" points=\"13.6035,-243.5 13.6035,-287.5 203.9072,-287.5 203.9072,-243.5 13.6035,-243.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0967\" y=\"-261.3\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64.5898,-243.5 64.5898,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4243\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64.5898,-265.5 120.2588,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4243\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-243.5 120.2588,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.083\" y=\"-272.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-265.5 203.9072,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.083\" y=\"-250.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 4825030896&#45;&gt;4315335200 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>4825030896-&gt;4315335200</title>\n",
       "<path d=\"M108.7554,-324.3664C108.7554,-316.1516 108.7554,-306.6579 108.7554,-297.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.2555,-297.6068 108.7554,-287.6068 105.2555,-297.6069 112.2555,-297.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 15319460216 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>15319460216</title>\n",
       "<polygon fill=\"none\" points=\"7.7656,-162.5 7.7656,-206.5 209.7451,-206.5 209.7451,-162.5 7.7656,-162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0967\" y=\"-180.3\">Dropout</text>\n",
       "<polyline fill=\"none\" points=\"70.4277,-162.5 70.4277,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2622\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"70.4277,-184.5 126.0967,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2622\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"126.0967,-162.5 126.0967,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9209\" y=\"-191.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"126.0967,-184.5 209.7451,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9209\" y=\"-169.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 4315335200&#45;&gt;15319460216 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>4315335200-&gt;15319460216</title>\n",
       "<path d=\"M108.7554,-243.3664C108.7554,-235.1516 108.7554,-225.6579 108.7554,-216.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.2555,-216.6068 108.7554,-206.6068 105.2555,-216.6069 112.2555,-216.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 15319691616 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>15319691616</title>\n",
       "<polygon fill=\"none\" points=\"13.6035,-81.5 13.6035,-125.5 203.9072,-125.5 203.9072,-81.5 13.6035,-81.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0967\" y=\"-99.3\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64.5898,-81.5 64.5898,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4243\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64.5898,-103.5 120.2588,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4243\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-81.5 120.2588,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.083\" y=\"-110.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-103.5 203.9072,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.083\" y=\"-88.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 15319460216&#45;&gt;15319691616 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>15319460216-&gt;15319691616</title>\n",
       "<path d=\"M108.7554,-162.3664C108.7554,-154.1516 108.7554,-144.6579 108.7554,-135.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.2555,-135.6068 108.7554,-125.6068 105.2555,-135.6069 112.2555,-135.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 15320015704 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>15320015704</title>\n",
       "<polygon fill=\"none\" points=\"8.5483,-.5 8.5483,-44.5 208.9624,-44.5 208.9624,-.5 8.5483,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46.0967\" y=\"-18.3\">Activation</text>\n",
       "<polyline fill=\"none\" points=\"83.645,-.5 83.645,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"111.4795\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"83.645,-22.5 139.314,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"111.4795\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"139.314,-.5 139.314,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"174.1382\" y=\"-29.3\">(None, 2)</text>\n",
       "<polyline fill=\"none\" points=\"139.314,-22.5 208.9624,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"174.1382\" y=\"-7.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 15319691616&#45;&gt;15320015704 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>15319691616-&gt;15320015704</title>\n",
       "<path d=\"M108.7554,-81.3664C108.7554,-73.1516 108.7554,-63.6579 108.7554,-54.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.2555,-54.6068 108.7554,-44.6068 105.2555,-54.6069 112.2555,-54.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(w2v_dnn,\n",
    "                 show_shapes = True,\n",
    "                 show_layer_names = False,\n",
    "                 rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training, Prediction and Performance Evaluatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 3500 samples\n",
      "Epoch 1/5\n",
      "31500/31500 [==============================] - 5s 168us/step - loss: 0.3080 - acc: 0.8705 - val_loss: 0.2990 - val_acc: 0.8731\n",
      "Epoch 2/5\n",
      "31500/31500 [==============================] - 4s 129us/step - loss: 0.2837 - acc: 0.8850 - val_loss: 0.2985 - val_acc: 0.8691\n",
      "Epoch 3/5\n",
      "31500/31500 [==============================] - 4s 127us/step - loss: 0.2786 - acc: 0.8874 - val_loss: 0.3002 - val_acc: 0.8751\n",
      "Epoch 4/5\n",
      "31500/31500 [==============================] - 4s 127us/step - loss: 0.2697 - acc: 0.8911 - val_loss: 0.2990 - val_acc: 0.8749\n",
      "Epoch 5/5\n",
      "31500/31500 [==============================] - 4s 126us/step - loss: 0.2631 - acc: 0.8921 - val_loss: 0.3029 - val_acc: 0.8746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x39137fcc0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "w2v_dnn.fit(avg_wv_train_features,\n",
    "            y_train, \n",
    "            epochs=5, \n",
    "            batch_size=batch_size,\n",
    "            shuffle=True, \n",
    "            validation_split=0.1, \n",
    "            verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8837\n",
      "Precision: 0.8839\n",
      "Recall: 0.8837\n",
      "F1 Score: 0.8836\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.87      0.90      0.89      7510\n",
      "   negative       0.89      0.87      0.88      7490\n",
      "\n",
      "avg / total       0.88      0.88      0.88     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6726      784\n",
      "        negative        961     6529\n"
     ]
    }
   ],
   "source": [
    "y_pred = w2v_dnn.predict_classes(avg_wv_test_features)\n",
    "predictions = label_encoded.inverse_transform(y_pred)\n",
    "meu.display_model_performance_metrics(true_labels = test_sentiments,\n",
    "                                      predicted_labels = predictions,\n",
    "                                      classes = ['positive', 'negative'])\n",
    "\n",
    "# The results show us that we have obtained a model accuracy and F1-score of 88%,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build and train a DNN model for our GloVe based features\n",
    "glove_dnn = construct_deepnn_architecture(num_input_features=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 3500 samples\n",
      "Epoch 1/5\n",
      "31500/31500 [==============================] - 4s 137us/step - loss: 0.6481 - acc: 0.6215 - val_loss: 0.5955 - val_acc: 0.6794\n",
      "Epoch 2/5\n",
      "31500/31500 [==============================] - 4s 113us/step - loss: 0.5927 - acc: 0.6842 - val_loss: 0.5710 - val_acc: 0.6949\n",
      "Epoch 3/5\n",
      "31500/31500 [==============================] - 4s 112us/step - loss: 0.5692 - acc: 0.7036 - val_loss: 0.5711 - val_acc: 0.6989\n",
      "Epoch 4/5\n",
      "31500/31500 [==============================] - 4s 111us/step - loss: 0.5619 - acc: 0.7111 - val_loss: 0.5571 - val_acc: 0.7043\n",
      "Epoch 5/5\n",
      "31500/31500 [==============================] - 3s 108us/step - loss: 0.5661 - acc: 0.7091 - val_loss: 0.5414 - val_acc: 0.7251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3919fe160>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train DNN model on GloVe training features\n",
    "batch_size = 100\n",
    "glove_dnn.fit(train_glove_features, y_train, epochs=5, batch_size=batch_size, \n",
    "              shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8837\n",
      "Precision: 0.8839\n",
      "Recall: 0.8837\n",
      "F1 Score: 0.8836\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.87      0.90      0.89      7510\n",
      "   negative       0.89      0.87      0.88      7490\n",
      "\n",
      "avg / total       0.88      0.88      0.88     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6726      784\n",
      "        negative        961     6529\n"
     ]
    }
   ],
   "source": [
    "y_pred = glove_dnn.predict_classes(test_glove_features)\n",
    "meu.display_model_performance_metrics(\n",
    "    true_labels=test_sentiments, \n",
    "    predicted_labels=predictions,\n",
    "    classes=['positive', 'negative'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
